{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#test run with Google Colab T4 GPU\n",
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3H6EeNH8Eawg",
        "outputId": "97f339a0-4f25-4d70-dbcb-df8941893f55"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.3.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.12)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.3.1-py3-none-any.whl (484 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m484.9/484.9 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-3.3.1 dill-0.3.8 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#upload kaggle.json\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "0HoEBwYpRcAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle"
      ],
      "metadata": {
        "id": "rXLPO7jjRpRf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#move to dir\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "nL-91IZpR8L0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#download dataset\n",
        "!kaggle datasets download -d aibloy/fairface/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaNaYYy9SLV-",
        "outputId": "e01913da-58ad-44d7-9629-04e6e5ec1b3f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/aibloy/fairface/versions/\n",
            "License(s): unknown\n",
            "Downloading fairface.zip to /content\n",
            " 97% 532M/550M [00:05<00:00, 113MB/s]\n",
            "100% 550M/550M [00:05<00:00, 105MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip fairface.zip -d /content/dataset/"
      ],
      "metadata": {
        "id": "hhKkvj18Sazr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rOCX5Ly7OdcU",
        "outputId": "288f30db-13d5-4a96-8009-3d36affbf400",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data Columns: Index(['file', 'age', 'gender', 'race', 'service_test'], dtype='object')\n",
            "Validation Data Columns: Index(['file', 'age', 'gender', 'race', 'service_test'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load train and validation datasets separately\n",
        "train_df = pd.read_csv('/content/dataset/FairFace/train_labels.csv')\n",
        "val_df = pd.read_csv('/content/dataset/FairFace/val_labels.csv')\n",
        "\n",
        "print(\"Train Data Columns:\", train_df.columns)  # Check if 'file' and 'race_encoded' exist\n",
        "print(\"Validation Data Columns:\", val_df.columns)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-XtTCg_jOdcY",
        "outputId": "2d59d6d7-5493-43b7-f903-ea9747194218",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Race Mapping: {'Black': 0, 'East Asian': 1, 'Indian': 2, 'Latino_Hispanic': 3, 'Middle Eastern': 4, 'Southeast Asian': 5, 'White': 6}\n"
          ]
        }
      ],
      "source": [
        "# Convert race labels to numbers\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Encode race labels as numerical values\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "train_df['race_encoded'] = label_encoder.fit_transform(train_df['race'])\n",
        "val_df['race_encoded'] = label_encoder.transform(val_df['race'])  # Use same encoding\n",
        "\n",
        "\n",
        "# Mapping of race categories\n",
        "# zip() pairs each category with its corresponding number and dict() creates a dictionary from the pairs fir easy reference\n",
        "race_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
        "print(\"Race Mapping:\", race_mapping)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AIx6DKW1Odca",
        "outputId": "c32b0fea-48d2-449c-c936-5ee7b5212970",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample filenames from train_df:\n",
            "0    train/1.jpg\n",
            "1    train/2.jpg\n",
            "2    train/3.jpg\n",
            "3    train/4.jpg\n",
            "4    train/5.jpg\n",
            "Name: file, dtype: object\n",
            "\n",
            "Files in training image directory:\n",
            "['69615.jpg', '8261.jpg', '21967.jpg', '41679.jpg', '11406.jpg']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Print the first few file names from the DataFrame\n",
        "print(\"Sample filenames from train_df:\")\n",
        "print(train_df['file'].head())\n",
        "\n",
        "# List some actual image files from the directory\n",
        "TRAIN_IMG_DIR = r\"/content/dataset/FairFace/train\"\n",
        "print(\"\\nFiles in training image directory:\")\n",
        "print(os.listdir(TRAIN_IMG_DIR)[:5])  # List the first 5 files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "z_qswM8dOdca"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Define paths to image directories\n",
        "TRAIN_IMG_DIR = r\"/content/dataset/FairFace/train\"\n",
        "VAL_IMG_DIR = r\"/content/dataset/FairFace/val\"\n",
        "\n",
        "\n",
        "# Function to load images in batches\n",
        "def image_generator(df, img_dir, batch_size=64):\n",
        "    while True:  # Infinite loop for batch generation\n",
        "        for i in range(0, len(df), batch_size):\n",
        "            batch_df = df.iloc[i:i+batch_size]  # Get batch\n",
        "            images = []\n",
        "            labels = []\n",
        "\n",
        "            for _, row in batch_df.iterrows():\n",
        "                filename = row['file'].replace(\"train/\", \"\").replace(\"val/\", \"\")\n",
        "                img_path = os.path.join(img_dir, filename)\n",
        "\n",
        "                img = cv2.imread(img_path)\n",
        "                if img is None:\n",
        "                    continue  # Skip missing images\n",
        "\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
        "                img = img.astype('float32') / 255.0  # Normalize\n",
        "\n",
        "                images.append(img)\n",
        "                labels.append(row['race_encoded'])\n",
        "\n",
        "            yield np.array(images), np.array(labels)  # Return batch\n",
        "\n",
        "# Create generators for training and validation\n",
        "train_gen = image_generator(train_df, TRAIN_IMG_DIR, batch_size=32)\n",
        "val_gen = image_generator(val_df, VAL_IMG_DIR, batch_size=32)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "IMKCKWTsOdcb",
        "outputId": "5b2a1d91-3229-4f4c-da8f-5e08d291a43a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch Shape: (32, 224, 224, 3) (32,)\n"
          ]
        }
      ],
      "source": [
        "# Get the first batch of images from the training generator\n",
        "X_batch, y_batch = next(train_gen)\n",
        "\n",
        "# Print shape of the batch to verify\n",
        "print(\"Batch Shape:\", X_batch.shape, y_batch.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "1Wthl28uOdcb",
        "outputId": "5c1dc9a1-61ef-4c76-b678-ea0478023227",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available: 1\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Lt-6_XDwOdcc",
        "outputId": "28e324c9-46e8-4fbe-fc8c-73a026353265",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 56ms/step - accuracy: 0.1883 - loss: 1.9878 - val_accuracy: 0.2912 - val_loss: 1.8192\n",
            "Epoch 2/10\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 80ms/step - accuracy: 0.2863 - loss: 1.8160 - val_accuracy: 0.3475 - val_loss: 1.6766\n",
            "Epoch 3/10\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 53ms/step - accuracy: 0.3429 - loss: 1.6823 - val_accuracy: 0.3916 - val_loss: 1.6189\n",
            "Epoch 4/10\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 54ms/step - accuracy: 0.3530 - loss: 1.6563 - val_accuracy: 0.4047 - val_loss: 1.5303\n",
            "Epoch 5/10\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 79ms/step - accuracy: 0.3642 - loss: 1.6257 - val_accuracy: 0.4172 - val_loss: 1.5414\n",
            "Epoch 6/10\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 60ms/step - accuracy: 0.3848 - loss: 1.5872 - val_accuracy: 0.4047 - val_loss: 1.5187\n",
            "Epoch 7/10\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 53ms/step - accuracy: 0.3854 - loss: 1.5637 - val_accuracy: 0.4103 - val_loss: 1.5014\n",
            "Epoch 8/10\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 52ms/step - accuracy: 0.3980 - loss: 1.5370 - val_accuracy: 0.4184 - val_loss: 1.4706\n",
            "Epoch 9/10\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 52ms/step - accuracy: 0.4072 - loss: 1.5268 - val_accuracy: 0.4412 - val_loss: 1.4464\n",
            "Epoch 10/10\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 52ms/step - accuracy: 0.4081 - loss: 1.5139 - val_accuracy: 0.4141 - val_loss: 1.4804\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a2e9cd1ae50>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# CNN ARCHITECTURE\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Define the CNN model\n",
        "model = Sequential([\n",
        "    # First Convolutional Block\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    MaxPooling2D(pool_size=(2,2)),\n",
        "\n",
        "    # Second Convolutional Block\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2,2)),\n",
        "\n",
        "    # Third Convolutional Block\n",
        "    Conv2D(128, (3,3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2,2)),\n",
        "\n",
        "    # Fully Connected Layers\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),  # Prevent overfitting\n",
        "    Dense(7, activation='softmax')  # 7 classes (one per race category)\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "\n",
        "# Use below if your PC is fast\n",
        "# model.fit(\n",
        "#     train_gen,\n",
        "#     validation_data=val_gen,\n",
        "#     steps_per_epoch=len(train_df) // 64,  # Batches per epoch\n",
        "#     validation_steps=len(val_df) // 64,\n",
        "#     epochs=10\n",
        "# )\n",
        "\n",
        "model.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    steps_per_epoch=500,  # Lower total steps per epoch\n",
        "    validation_steps=100,  # Lower validation steps\n",
        "    epochs=10\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "5JJX16hCOdcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1126df2-1b11-4e8f-cd25-1080108bff72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "model.save(\"race_classifier_model_v1.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"race_classifier_model_v1.keras\")"
      ],
      "metadata": {
        "id": "6BToXEyybCgc"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Oxford-EDI-Initiative/Face.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piZhtRfhc_8u",
        "outputId": "15982b29-89de-495e-fc2f-6cf06dcd58a6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Face'...\n",
            "remote: Enumerating objects: 34, done.\u001b[K\n",
            "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 34 (delta 14), reused 3 (delta 1), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (34/34), 494.92 KiB | 1.45 MiB/s, done.\n",
            "Resolving deltas: 100% (14/14), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/race_classifier_model_v1.h5 /content/Face\n",
        "!mv /content/race_classifier_model_v1.keras /content/Face"
      ],
      "metadata": {
        "id": "o8tRO0rEdGqy"
      },
      "execution_count": 17,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}